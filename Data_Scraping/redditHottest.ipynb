{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 3: Data Pre-processing\n",
    "\n",
    "COSC2671 Social Media and Network Analytics\n",
    "\n",
    "Jeffrey Chan, RMIT University, 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This automatically reloads the client information if there are changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport redditClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redditClient import redditClient\n",
    "import praw\n",
    "import json\n",
    "import functools\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters used throughout this notebook.\n",
    "Usually useful to have these parameters in one cell (and one location) and can edit them as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subreddit name we interested in getting the hot submissions\n",
    "sSubredditName = 'NVDA_Stock'\n",
    "# maximum number of hot submissions\n",
    "hotLimit = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct Reddit client then print our name to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehensive-End522\n"
     ]
    }
   ],
   "source": [
    "# construct Reddit client\n",
    "client = redditClient()\n",
    "\n",
    "# sanity check, you should see your own username printed out\n",
    "print(client.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=None)\n",
    "def reddit_api_response(sSubredditName, hotLimit):  \n",
    "    # specify which subreddit we are interested in\n",
    "    subreddit = client.subreddit(sSubredditName)\n",
    "    # Convert dates to timestamps\n",
    "    data = []\n",
    "    # print out the hot submisisons\n",
    "    # subreddit.comments.replace_more(limit=None)\n",
    "    # expand all the comments\n",
    "    for submission in subreddit.hot(limit=hotLimit):\n",
    "        for comment in submission.comments.list(): #only take last 10 comments\n",
    "            comments=[]\n",
    "            comment_data={\n",
    "                \"author\": comment.author.name if comment.author else \"No Author\",\n",
    "                \"created\": comment.created_utc,\n",
    "                \"text\": comment.body\n",
    "            }\n",
    "            comments.append(comment_data)\n",
    "    \n",
    "        # print title, but we can print other information as well\n",
    "        post_data = {\n",
    "        \"title\": submission.title,\n",
    "        \"author\": submission.author.name if submission.author else \"No Author\",\n",
    "        \"score\": submission.score,\n",
    "        \"comments\":comments,\n",
    "        \"created\":submission.created_utc\n",
    "        }\n",
    "        data.append(post_data)\n",
    "    print(data)\n",
    "    final_data = {\"submissions\":data}\n",
    "    with open(\"nvidia_stock_data.json\", \"w\") as json_file:\n",
    "        json.dump(final_data, json_file)\n",
    "    print(\"Data saved to nvidia_stock_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': '✅ Daily Chat Thread and Discussion ✅', 'author': 'AutoModerator', 'score': 11, 'comments': [{'author': 'ruafukreddit', 'created': 1723562926.0, 'text': 'The best time to buy was 20 years ago. The 2nd best time, is now.'}], 'created': 1723521632.0}, {'title': \"BofA names Nvidia top 'rebound' stock in 2024 chip comeback\", 'author': 'Avinates', 'score': 160, 'comments': [{'author': 'redditissocoolyoyo', 'created': 1723576935.0, 'text': \"I'm loving all the people that panic sold. This is the name of the game the same old trick for decades.\"}], 'created': 1723551979.0}, {'title': 'NVDA forward PEG based on projections from Morgan Stanley', 'author': 'AideMobile7693', 'score': 23, 'comments': [{'author': 'Ragnarok-9999', 'created': 1723592788.0, 'text': 'Level of uncertainty with companies like NVDA is very very high with so much competition and questions about business value, etc, makes it very difficult to do forward projection to next 2 years'}], 'created': 1723586470.0}, {'title': 'Sour grapes guy.', 'author': 'UltimateFauchelevent', 'score': 25, 'comments': [{'author': 'luzzi5luvmywatches', 'created': 1723595494.0, 'text': 'got it TY'}], 'created': 1723567108.0}, {'title': \"What's your plan before/after earnings?\", 'author': 'shinchan108', 'score': 42, 'comments': [{'author': 'A_Wizard1717', 'created': 1723594117.0, 'text': 'sure man, I bought the 92 dip last week'}], 'created': 1723557035.0}]\n",
      "Data saved to nvidia_stock_data.json\n"
     ]
    }
   ],
   "source": [
    "reddit_api_response(sSubredditName, hotLimit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
